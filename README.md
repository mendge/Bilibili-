hdu创新实践小项目


# bilibili视频及相关信息下载

技术路线以及实现方案
项目准备
（1）	配置python3环境
（2）	配置youget环境
（3）	配置ffmpeg环境
（4）	安装python第三方库：lxml、json、re、os、pymysql、selenium、flask

爬取视频基本信息
其实本次项目中最基本的功能就是对单个视频基本信息的获取，爬虫的目的就是对基本数据进行分析，这是爬虫的价值所在。但是由于精力和时间原因，我并未学习并实现相关分析板块的功能。
对于B站视频，其基本信息都是存在网页源代码当中的，我们获取网页源代码后利用text()方法将其转为文本形式并将其利用etree库的函数构造成解析数，在进行xpath解析。在这里不推荐直接观察源代码结构获得xpath路径，效率过于低下。可以直接在网页中检查后审查元素，找到相应节点后，直接点击复制xpath路径。通过这个方法分析视频网页信息结构，将要爬取的基本信息路径抽取出来，视频网页的布局具有统一性，我们可以将其应用到所有页面的解析中。在这里，我们不直接将获取到的基本信息存入数据库，因为如果网页结构有变，我们部分信息存入了数据库而部分没有，就会在二次爬取该页面时出现数据冗余的现象。所以更好的选择是将其作为单个视频解析类的一个方法，并将获取到的基本信息封装成字典返回。





 ![image](https://user-images.githubusercontent.com/76037078/165460007-ed49a335-5c13-487e-976a-9a65c9dca90f.png)




爬取视频和封面图片
	下载视频和封面图片最重要就是url地址，获取图片地址可以通过检查中的元素审查得到。但是视频地址就无法通过这种方式获取。我们需要先通过网络抓包获取视频url地址，但是不可能在爬取每一个视频的时候都去手动获取视频地址，这显然违背了爬虫的初衷：自动化爬取。将获取的视频url复制在视频网页源代码中查找，可以找到其位置。解析位置周围的字串后，我们用re中的正则匹配将其匹配下来，于是视频url地址就获取到了。
	下载视频和封面图片我做了两种方案。
	第一种就是利用开源工具youget。在python中调用os库执行youget下载命令。值得注意的是，因为我们的youget下载命令是需要配置参数的，所以我们需要将要爬取的网页视频或者图片url、保存文件路径以及保存的别名通过字符串格式化做好拼装。Youget稳定，下载速度也正常。
	第二种就是手写下载类方法。需要用到解析好的视频url地址和音频url地址（其获取方式同视频），直接利用requests分别请求这两个url的content，即url中储存的二进制数据。但是，在请求前我们一定要配置请求头中的referer为视频网页页面的url。为防止盗链，B站只允许自己的网站访问自己的视频服务器，服务器每次取到Referer来判断一下是不是自己的域名跳转来的，如果是就继续访问，不是就拦截。获取到视频音频的二进制数据后写入爬虫项目指定的文件路径，调用ffmpeg合并视频和音频，再删除原视频和原音频。很重要的一点是，当我们在创建文件为其命名的时候要注意不能含有特殊字符。所以我们的视频标题需要对特殊字符进行替换处理。例如/、\、:、*、?、’、|、>、<等。一个视频页面可能有多个视频。先判定能通过源代码否找到标志多视频的视频个数pn，若能则需要重构视频页面url，加上pn=x（1<=x<=pn），利用循环，调用下载单个视频的类方法下载多视频。
  
  
  
  
  
  
  
 ![image](https://user-images.githubusercontent.com/76037078/165460031-5545b437-070e-45ea-b9d6-2f48c4288bba.png)
 
 
 
 
![image](https://user-images.githubusercontent.com/76037078/165460068-7ae8d7d3-cc7f-4da1-a457-fae00d89203e.png)




爬取评论信息
	获取视频评论方法也有两种。
	第一种，借助Selenium工具实现鼠标下滑动态加载评论动态获取。配置好浏览器driver后对请求的页面用selenium提供的方法进行操作，不断下拉获取。然后返回列表。这种实现方法非常慢，在启动浏览器的时候花费的时间需要六秒钟左右，如过每个视频页面都通过这样获取，整个程序的运行速度就大大被拉低。若只启动一次，爬多个视频，那么必须先构造url，但是这样做就会出现新的问题，那就是评论的下载与该视频其他信息的下载不同步，可能会导致信息残缺。所以该方法被我淘汰。
	第二种则是直接解评论所在html页面的文本。要获取html文本必先需要存储评论的url地址。同样也是通过抓包，获取评论url地址，再分析参数。获取到的url无法请求到，需要删除不需要参数，可采用控制变量法。可以确定，其中有一个参数是特定的，其对应一个确定的视频。我们去视频页面源码中课搜索到该串数字。于是只需要将设定一个评论url模板，在爬取不同视频的评论时，拼接正则表达式匹配到视频对应的特定参数，并在末尾加上pn=x进行翻页。请求评论url后，将获取的html文本用json解析，就可获取评论。将其封装成列表返回。
  
  
  
 ![image](https://user-images.githubusercontent.com/76037078/165460094-630027c3-34fe-4652-87ed-6bdfac5451f8.png)




爬取搜索结果页url
利用控制变量法，将搜索结果页的url保留最重要的参数，再在url尾部拼接pn=x，可以进行搜索结果翻页。再通过获取每一页url的源码以及xpath解析获取某一页下的所以视频url，返回列表。




 ![image](https://user-images.githubusercontent.com/76037078/165460109-dc23b3db-677a-4377-a3e7-ad5f9be5333e.png)



爬取分区下url
分区下的视频列表是动态解析的，无法同获取搜索结果url一页利用网页源码解析和xpath一样。点进某分区下的一个分类，分析其url参数。其中一个特定的数字串对应的就是特定分区的特定分类，同样，这个特定数字串可以在分区html源码中正则匹配到。于是先通过正则表达式匹配，获得特定个数即类数对应的特定数字串。利用控制变量法分析出的最简洁类url模板拼接进特殊子串就能获取类url的html文本。同时，可以对类结果设置参数来调整返回的url列表格式，比如设置每页html中的视频url个数：pagesize=50、设置html中是按热度还是时间展示视频url：参数'order': 'click'，以及通过page=x进行翻页。逐页对html采用json解析，将获取的视频url添加进返回列表，最后返回。




 ![image](https://user-images.githubusercontent.com/76037078/165460127-4ce97d03-6f8d-47c5-a520-20a5d64d257d.png)


连接数据库：
	明确存储信息：BV号、视频标题、上传日期、观看数、弹幕数、点赞数、投币数、转发数、收藏数以及视频相应评论（热评和最近评论）。
	数据库准备工作：创建新数据库，根据爬取数据的相应结构建表。
Python连接数据库。通过pymysql库中的connect()传入所要连接的数据库的参数，包括端口、密码和解码方式等来连接数据库。分别用两个类处理分区写和搜索结果写来写入视频的基本信息以及评论信息。先将爬取到的数据利用字符串格式化拼凑出sql语句，再生成的游标execute SQL语句，数据就能插进数据库中了。值得注意的是，一个视频可能在多个分区或者搜索结果中出现，为防止数据库插入失败错误，需要捕获重复插入异常执行pass。值得注意的是：插入的评论可能会过长，B站的评论字数的几乎没有限制，而建表时考虑到内存的开销，评论内容字段不可能特别大，谨防万一，我们需要捕获一个插入数据过大异常。






基本信息：![image](https://user-images.githubusercontent.com/76037078/165460176-a4b7f1c3-aac5-4bc7-9ea7-f61036c7a571.png)





评论信息：![image](https://user-images.githubusercontent.com/76037078/165460215-f3c5e08d-7668-43a5-b761-aaa2b74bc0a9.png)


 
